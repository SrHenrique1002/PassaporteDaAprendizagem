import streamlit as sl
import os
import time
import re
from pydantic import BaseModel, Field

# Importa√ß√µes LangChain e Google Gemini
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings 
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser 
from langchain_core.runnables import RunnablePassthrough
from dotenv import load_dotenv

# Garante que o diret√≥rio 'uploaded' exista e carrega vari√°veis de ambiente
os.makedirs("uploaded", exist_ok=True) 
load_dotenv()

# ==============================================================================
# 0. CONSTANTES E ESTRUTURAS DE DADOS
# ==============================================================================

# Defini√ß√£o dos diret√≥rios
CURRICULUM_PDF_DIR = "curriculos_base" # Pasta onde seus PDFs de curr√≠culo devem estar
FAISS_INDEX_DIR = "faiss_indices"
os.makedirs(CURRICULUM_PDF_DIR, exist_ok=True) # Garante que a pasta de curr√≠culos exista
os.makedirs(FAISS_INDEX_DIR, exist_ok=True)

class Defasagem(BaseModel):
    """Esquema de sa√≠da estruturada para a an√°lise do Boletim."""
    ano: str = Field(description="O ano letivo do estudante (ex: '7¬∫ ano'). Deve ser entre 6¬∫ e 9¬∫ ano.")
    # NOVO CAMPO ADICIONADO:
    bimestre: str = Field(description="O bimestre letivo da defasagem (ex: '3¬∫ bimestre'). Deve ser entre 1¬∫ e 4¬∫.") 
    defasagem_foco: str = Field(description="O termo de busca ideal para a grade curricular (ex: 'Grade curricular completa de Matem√°tica do 3¬∫ Bimestre').")
    motivo: str = Field(description="Breve justificativa baseada no boletim (ex: 'M√©dia de 4.0 na unidade 3 em √Ålgebra').")


# ==============================================================================
# 1. FUN√á√ïES DE CONFIGURA√á√ÉO E LLM
# ==============================================================================

def load_prompt_rag():
    """Carrega o template de prompt RAG, com regra de separa√ß√£o para as abas."""
    prompt = """Voc√™ √© um Analista Pedag√≥gico e Avaliador Curricular de Matem√°tica. 
Sua miss√£o √© criar um Pr√©-Question√°rio de 15 perguntas de diagn√≥stico para um aluno do **{ano}**, focado em identificar a defasagem exata no t√≥pico: '{defasagem_foco}'.

# REGRAS DE GERA√á√ÉO:
1. **Foco Diagn√≥stico Amplo:** As 15 perguntas devem ser projetadas para testar os conceitos mais fundamentais e diversos presentes no 'Contexto Curricular Detalhado'.
2. **Contexto Exclusivo:** Use APENAS o 'Contexto Curricular Detalhado'.
3. **Formato de Sa√≠da OBRIGAT√ìRIO:**
    a. Comece com a **se√ß√£o de Perguntas**.
    b. Ap√≥s a √∫ltima pergunta e antes de iniciar as Respostas, insira **EXATAMENTE** o delimitador: `---FIM_PERGUNTAS---`.
    c. Ap√≥s o delimitador, inicie a se√ß√£o de Respostas Detalhadas e An√°lise.

Contexto Curricular Detalhado (curr√≠culo do {ano}): {context}
"""
    prompt = ChatPromptTemplate.from_template(prompt)
    return prompt

def load_llm():
    """Carrega e retorna o modelo de linguagem (LLM) do Gemini."""
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)
    return llm

def format_docs(docs):
    """Formata os documentos recuperados em uma √∫nica string de contexto."""
    return "\n\n".join(doc.page_content for doc in docs)

# ==============================================================================
# 2. FUN√á√ïES DE PROCESSAMENTO DE DATAS (Indexa√ß√£o e An√°lise)
# ==============================================================================

def extract_year_from_filename(filename):
    """Extrai o ano letivo (6, 7, 8 ou 9) e o bimestre (1-4) do nome do arquivo de forma mais robusta."""
    
    # Padroniza o nome do arquivo: min√∫sculas, remove '¬∫', '¬∞' e ' '
    # Ex: 'EF-Matematica-6ano-1¬∞bimestre.pdf' -> 'ef-matematica-6ano-1bimestre.pdf'
    cleaned_filename = filename.lower().replace('¬∫', '').replace('¬∞', '') 

    # 1. Extrai o Ano (Year) - procura por (digito 6-9) seguido de 'ano'
    # O \s* permite encontrar '6ano' ou '6 ano'
    match_year = re.search(r'([6-9])\s*ano', cleaned_filename)
    year_key = None
    if match_year:
        year = match_year.group(1)
        year_key = f"{year}¬∫ ano"
        
    # 2. Extrai o Bimestre (Bimestre) - procura por (digito 1-4) seguido de 'bimestre'
    match_bimestre = re.search(r'([1-4])\s*bimestre', cleaned_filename)
    bimestre_key = None
    if match_bimestre:
        bimestre = match_bimestre.group(1)
        bimestre_key = f"B{bimestre}" # Ex: B1
        
    # Combina e retorna a chave se ambos forem encontrados
    if year_key and bimestre_key:
        return f"{year_key} {bimestre_key}"
        
    # Se a extra√ß√£o falhou (apenas ano, apenas bimestre, ou nenhum)
    return None

def get_sanitized_index_key(year_key: str) -> str:
    """Converte a chave leg√≠vel (ex: '6¬∫ ano B3') para o nome de pasta FAISS seguro (ex: '6ano_B3')."""
    # Remove '¬∫ ano', remove espa√ßos e converte para min√∫sculas para seguran√ßa.
    sanitized = year_key.lower().replace('¬∫ ano', 'ano').replace(' ', '_')
    return f"faiss_matematica_{sanitized}"

def initialize_knowledge_base():
    """Verifica a pasta de curr√≠culos, indexa PDFs e retorna o status."""
    embeddings = GoogleGenerativeAIEmbeddings(model="text-embedding-004")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size = 512, chunk_overlap = 30, length_function = len, separators= ["\n\n", "\n", ".", " "]
    )
    
    indexed_years = set()
    pdf_files = [f for f in os.listdir(CURRICULUM_PDF_DIR) if f.endswith(".pdf")]
    
    if not pdf_files:
        return "Nenhum PDF de curr√≠culo encontrado no diret√≥rio 'curriculos_base'. Adicione os arquivos para iniciar."

    for pdf_name in pdf_files:
        full_path = os.path.join(CURRICULUM_PDF_DIR, pdf_name)
        year_key = extract_year_from_filename(pdf_name)
        
        if not year_key:
            sl.warning(f"Ignorando '{pdf_name}'. N√£o foi poss√≠vel identificar o ano (6¬∫-9¬∫).", icon="‚ö†Ô∏è")
            continue

        index_name = get_sanitized_index_key(year_key) # Ex: 'faiss_matematica_6ano_b3'
        index_path = os.path.join(FAISS_INDEX_DIR, index_name)
        
        # 1. Verifica se o √≠ndice FAISS j√° existe
        if os.path.exists(index_path):
            indexed_years.add(year_key)
            continue 

        # 2. Se n√£o existe, indexa e salva
        try:
            loader = PyPDFLoader(full_path)
            text_chunks = loader.load_and_split(text_splitter=text_splitter)
            
            vectorstore = FAISS.from_documents(documents=text_chunks, embedding=embeddings)
            vectorstore.save_local(index_path)
            indexed_years.add(year_key)
            
        except Exception as e:
            sl.error(f"Erro ao indexar o curr√≠culo do {year_key} ({pdf_name}): {e}", icon="‚ùå")
            
    if indexed_years:
        return f"Curr√≠culos indexados e prontos para consulta: {', '.join(sorted(list(indexed_years)))}."
    else:
        return "Nenhum curr√≠culo v√°lido foi indexado. Verifique os PDFs e seus nomes."


def load_vector_store_by_year(year: str):
    """Carrega o Vector Store FAISS correto do disco."""
    embeddings = GoogleGenerativeAIEmbeddings(model="text-embedding-004")
    
    index_name = get_sanitized_index_key(year) # Ex: 'faiss_matematica_6ano_b3'
    index_path = os.path.join(FAISS_INDEX_DIR, index_name)
    
    if not os.path.exists(index_path):
        # Falha no carregamento (√≠ndice n√£o existe)
        return None
        
    try:
        # Usa allow_dangerous_deserialization=True para carregamento seguro do FAISS
        vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)
        return vectorstore
    except Exception:
        # Falha no carregamento (√≠ndice corrompido)
        return None
        
def analyze_boletim(boletim_text, llm):
    """Analisa o texto do boletim usando LLM e retorna a defasagem estruturada."""
    
    # 1. Definir o LLM com o formato de sa√≠da estruturada
    llm_structured = llm.with_structured_output(Defasagem)
    
    # 2. Definir o prompt simplificado
    analysis_prompt = ChatPromptTemplate.from_messages([
        ("system", 
        """Voc√™ √© um Analista Pedag√≥gico especialista em Matem√°tica, anos 6¬∫ ao 9¬∫. 
        Sua tarefa √© analisar o desempenho do aluno no boletim fornecido e identificar:
        1. O **Ano** (6¬∫ ao 9¬∫) e o **Bimestre** (1¬∫ ao 4¬∫) em que o aluno obteve o pior desempenho em Matem√°tica.
        2. O **termo de busca** ideal para a grade curricular desse per√≠odo (`defasagem_foco`).

        # REGRAS DE INFER√äNCIA E SA√çDA:
        * Se o boletim **N√ÉO** detalhar unidades/t√≥picos (apenas m√©dias bimestrais), use a frase de busca gen√©rica: 'Grade curricular completa de Matem√°tica do BIMESTRE X'.
        * Se o boletim **DETALHAR** o t√≥pico (e a defasagem for clara), use o t√≥pico espec√≠fico (ex: 'Geometria Espacial').
        * Voc√™ DEVE retornar uma sa√≠da estruturada v√°lida. Nunca retorne 'N√£o informado' nos campos `ano`, `bimestre` ou `defasagem_foco`.

        Instru√ß√µes Finais: Retorne a sa√≠da estritamente no formato JSON, conforme o esquema Pydantic.

        """),
        ("user", "Analise o texto do boletim abaixo e extraia o ano e a defasagem de Matem√°tica:\n\n{boletim_text}")])
    
    # 3. Criar a cadeia
    chain = (analysis_prompt | llm_structured)
    
    try:
        # A invoca√ß√£o retorna diretamente o objeto Pydantic (Defasagem)
        result = chain.invoke({"boletim_text": boletim_text}) 
        return result
    except Exception as e:
        sl.error(f"Erro ao analisar o boletim (LLM): {e}", icon="‚ùå")
        return None

def extract_data_from_pdf(pdf_file):
    """Extrai texto do PDF do boletim."""
    try:
        # Nota: O 'uploaded' √© usado para salvar o Boletim temporariamente.
        save_uploadedfile(pdf_file) 
        loader = PyPDFLoader(os.path.join('uploaded', pdf_file.name))
        
        documents = loader.load() 
        full_text = "\n\n".join(doc.page_content for doc in documents)
        
        return full_text
    except Exception as e:
        sl.error(f"Erro ao carregar o PDF do Boletim: {e}", icon="‚ùå")
        return None

# ==============================================================================
# 3. FUN√á√ïES AUXILIARES DE STREAMLIT
# ==============================================================================

def initialize_session_state():
    """Inicializa o estado de sess√£o."""
    if "defasagem_data" not in sl.session_state: sl.session_state["defasagem_data"] = None 
    if "index_status" not in sl.session_state: sl.session_state["index_status"] = None # Status da indexa√ß√£o base
    
def save_uploadedfile(uploadedfile):
    """Salva o arquivo PDF enviado na pasta 'uploaded'."""
    with open(os.path.join("uploaded", uploadedfile.name), "wb") as f: f.write(uploadedfile.getbuffer())

def remove_files():
    """Remove arquivos PDF do diret√≥rio 'uploaded'."""
    path = os.path.join(os.getcwd(), 'uploaded')
    for file_name in os.listdir(path):
        file = os.path.join(path, file_name)
        if os.path.isfile(file) and file.endswith(".pdf"): os.remove(file)


# ==============================================================================
# 4. INTERFACE STREAMLIT E L√ìGICA PRINCIPAL
# ==============================================================================

if __name__ == '__main__':
    
    initialize_session_state()
    llm = load_llm()
    
    sl.title("üî¨ Triagem Curricular por LLM (Diagn√≥stico de Boletim)")
    
    # 1. Inicializa√ß√£o Autom√°tica (Verifica/Cria √çndices FAISS)
    with sl.spinner("Verificando e indexando a Base Curricular local..."):
        if sl.session_state.index_status is None:
            sl.session_state.index_status = initialize_knowledge_base()
            
    # --- Sidebar ---
    with sl.sidebar:
        sl.markdown("## üìö Configura√ß√£o da Base Curricular")
        sl.markdown(f"**Status da Base RAG:**")
        
        if "Curr√≠culos indexados" in sl.session_state.index_status:
            sl.success(sl.session_state.index_status, icon="‚úÖ")
        else:
            sl.error(sl.session_state.index_status, icon="‚ùå")
            sl.markdown(f"**A√ß√£o necess√°ria:** Adicione os PDFs dos curr√≠culos (ex: `Curriculo_7ano.pdf`) na pasta `{CURRICULUM_PDF_DIR}`.")
    
    # --- Aplica√ß√£o Principal: An√°lise do Boletim e Gera√ß√£o ---
    
    sl.markdown("## üìà An√°lise do Boletim e Gera√ß√£o do Diagn√≥stico")
    
    if "Curr√≠culos indexados" not in sl.session_state.index_status:
        # Se a indexa√ß√£o falhou, n√£o permite o upload do Boletim
        sl.warning("üö® A base curricular n√£o est√° pronta. Por favor, corrija a configura√ß√£o na barra lateral.", icon="üö®")
    else:
        
        # Uso da key √∫nica para evitar DuplicateWidgetID
        boletim_pdf = sl.file_uploader(
            label='**1. Upload do Boletim do Estudante (PDF):**', 
            accept_multiple_files=False, 
            type=["pdf"],
            key="boletim_upload_key" 
        )

        if boletim_pdf and sl.button("Analisar Boletim e Gerar Question√°rio", key="analyze_and_generate"):
            
            # A. Extrair texto do Boletim
            boletim_text = extract_data_from_pdf(boletim_pdf)
            
            if boletim_text:
                sl.info("Boletim lido. Iniciando a an√°lise para identificar a defasagem...", icon="üîç")
                
                # B. Analisar o Boletim (LLM Chain 1)
                with sl.spinner("Identificando o foco da defasagem em Matem√°tica..."):
                    defasagem_result = analyze_boletim(boletim_text, llm)
                    sl.session_state.defasagem_data = defasagem_result
                
                if sl.session_state.defasagem_data:
                    def_data = sl.session_state.defasagem_data
                    sl.success(f"Defasagem identificada no **{def_data.ano}**: **{def_data.defasagem_foco}**.", icon="üí°")
                    sl.caption(f"Motivo (An√°lise do Boletim): {def_data.motivo}")
                    
                    # C. Mapeamento e Carregamento Din√¢mico do Vector Store (Etapa 2)
                    try:
                        # 1. Extrai o n√∫mero do bimestre e constr√≥i a chave de busca.
                        bimestre_match = re.search(r'[1-4]', def_data.bimestre)
                        if not bimestre_match:
                            raise ValueError("N√£o foi poss√≠vel extrair o n√∫mero do bimestre (1-4).")
                            
                        bimestre_num = bimestre_match.group(0) 
                        
                        # Chave composta usada para FAISS: Ex: '6¬∫ ano B3'
                        key_busca = f"{def_data.ano} B{bimestre_num}" 
                        
                    except Exception as e:
                        sl.error(f"Erro ao processar o Ano/Bimestre: {e}", icon="‚ùå")
                        sl.stop() # Interrompe a execu√ß√£o se a chave n√£o for v√°lida.

                    # 2. Carrega o Vector Store espec√≠fico.
                    with sl.spinner(f"Carregando base curricular espec√≠fica: **{key_busca}**..."):
                        knowledge_base_specific = load_vector_store_by_year(key_busca)
                        
                    if knowledge_base_specific is None:
                        sl.error(f"Falha no carregamento da base curricular de **{key_busca}**. O √≠ndice FAISS n√£o existe ou est√° corrompido.", icon="‚ùå")
                        sl.warning(f"Certifique-se de que o arquivo de curr√≠culo do **{def_data.ano}** e **{def_data.bimestre}** foi indexado corretamente na pasta `curriculos_base`.", icon="‚ö†Ô∏è")
                        sl.stop() # Interrompe a execu√ß√£o
                        
                    # D. Preparar e Executar o RAG (LLM Chain 2) - ETAPA 3
                    try:
                        prompt_rag = load_prompt_rag()
                        # k=10 ou mais pode ser mais adequado para o modo 'Grade Curricular Completa'
                        retriever = knowledge_base_specific.as_retriever(search_kwargs={"k": 10}) 
                        
                        with sl.spinner(f"Buscando conte√∫do curricular e gerando question√°rio de diagn√≥stico para {def_data.defasagem_foco}..."):
                            
                            # 1. Recupera o contexto relevante usando o t√≥pico de defasagem como query
                            retrieved_docs = retriever.invoke(def_data.defasagem_foco)
                            context_str = format_docs(retrieved_docs)
                            
                            # 2. Monta o input para o prompt com todas as vari√°veis
                            prompt_input = {
                                "context": context_str,
                                "defasagem_foco": def_data.defasagem_foco,
                                "ano": def_data.ano
                            }
                            
                            # 3. Executa a cadeia de gera√ß√£o
                            generation_chain = (prompt_rag | llm | StrOutputParser())
                            response = generation_chain.invoke(prompt_input) 
                        
                        # --- MODIFICA√á√ÉO DE INTERFACE AQUI ---
                        sl.subheader("2. Pr√©-Question√°rio de Diagn√≥stico Gerado üìù")

                        # 1. Tenta dividir o conte√∫do no delimitador
                        DELIMITER = "---FIM_PERGUNTAS---"
                        if DELIMITER in response:
                            perguntas_str, gabarito_str = response.split(DELIMITER, 1)
                        else:
                            # Se o LLM falhar e n√£o incluir o delimitador, exibe o conte√∫do completo nas duas abas
                            perguntas_str = response
                            gabarito_str = "Falha ao separar perguntas e gabarito. Conte√∫do completo na aba Perguntas."
                            sl.warning("O modelo LLM falhou ao inserir o delimitador. O question√°rio completo est√° na primeira aba.", icon="‚ö†Ô∏è")

                        # 2. Uso de abas para separar perguntas e respostas
                        tab1, tab2 = sl.tabs(["üìã Perguntas e Instru√ß√µes", "üîç Gabarito e An√°lise Pedag√≥gica"])

                        with tab1:
                            sl.markdown("### Question√°rio de Triagem R√°pida")
                            sl.markdown(perguntas_str) # Apenas as perguntas
                            
                        with tab2:
                            sl.markdown("### Gabarito e An√°lise")
                            sl.markdown(gabarito_str) # Apenas o gabarito


                        # E. Auditoria e Transpar√™ncia do RAG (Etapa 4 - NOVO)
                        with sl.expander("üìö Contexto Curricular Utilizado para Gera√ß√£o (Auditoria)"):
                            sl.markdown(context_str)
                        
                        sl.info(f"Question√°rio gerado com base no curr√≠culo do **{def_data.ano}** e no foco **{def_data.defasagem_foco}**.", icon="‚úÖ")
                        
                    except Exception as e:
                        sl.error(f"Ocorreu um erro ao processar o RAG: {e}", icon="‚ùå")
                        
                else: # O 'else' pertence ao 'if sl.session_state.defasagem_data:' (falha na Etapa B)
                    sl.error("N√£o foi poss√≠vel identificar a defasagem relevante no boletim.", icon="‚ùå")